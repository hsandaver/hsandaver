{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN9oOMaXTcO8gEXj2Mo/Ggz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsandaver/hsandaver/blob/main/marctobibframeconvertor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWFb2UvhHqwe"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install pymarc rdflib pyshacl\n",
        "\n",
        "from google.colab import files\n",
        "print(\"Please upload your MARC file (binary .mrc format):\")\n",
        "uploaded = files.upload()  # User uploads the MARC file\n",
        "\n",
        "from pymarc import MARCReader\n",
        "from rdflib import Graph, Namespace, URIRef, Literal, RDF\n",
        "\n",
        "# Define namespaces\n",
        "BF = Namespace(\"http://id.loc.gov/ontologies/bibframe/\")\n",
        "RDA = Namespace(\"http://rdaregistry.info/Elements/\")\n",
        "EX = Namespace(\"http://example.org/record/\")\n",
        "\n",
        "graph = Graph()\n",
        "graph.bind(\"bf\", BF)\n",
        "graph.bind(\"ex\", EX)\n",
        "graph.bind(\"rda\", RDA)\n",
        "\n",
        "print(\"Processing the MARC records...\")\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    with open(filename, 'rb') as fh:\n",
        "        reader = MARCReader(fh)\n",
        "        for record in reader:\n",
        "            if record['001']:\n",
        "                record_id = record['001'].value().strip()\n",
        "            else:\n",
        "                record_id = str(hash(record))\n",
        "\n",
        "            work_uri = URIRef(EX[f\"work/{record_id}\"])\n",
        "            instance_uri = URIRef(EX[f\"instance/{record_id}\"])\n",
        "\n",
        "            # Link Instance to Work\n",
        "            graph.add((instance_uri, BF.instanceOf, work_uri))\n",
        "\n",
        "            # Admin metadata fields\n",
        "            if record['003']:\n",
        "                graph.add((instance_uri, BF.adminMetadata, Literal(\"Control Number Identifier: \" + record['003'].value().strip())))\n",
        "            if record['005']:\n",
        "                graph.add((instance_uri, BF.adminMetadata, Literal(\"Date and Time of Latest Transaction: \" + record['005'].value().strip())))\n",
        "            if record['008']:\n",
        "                graph.add((instance_uri, BF.adminMetadata, Literal(\"Fixed-Length Data Elements: \" + record['008'].value().strip())))\n",
        "\n",
        "            # Leader might also be stored as admin data\n",
        "            graph.add((instance_uri, BF.adminMetadata, Literal(\"Leader: \" + str(record.leader).strip())))\n",
        "\n",
        "            # 007 fields as admin metadata notes\n",
        "            for f in record.get_fields('007'):\n",
        "                graph.add((instance_uri, BF.adminMetadata, Literal(\"Physical Characteristics (007): \" + f.value())))\n",
        "\n",
        "            # 040 Cataloging source\n",
        "            if record['040']:\n",
        "                vals = record['040'].get_subfields()\n",
        "                val = \"; \".join(v.strip() for v in vals if v and v.strip())\n",
        "                graph.add((instance_uri, BF.adminMetadata, Literal(\"Cataloging Source: \" + val)))\n",
        "\n",
        "            # Title (245)\n",
        "            if '245' in record:\n",
        "                title_field = record['245']\n",
        "                title_a = title_field['a'] if 'a' in title_field else \"\"\n",
        "                title_b = title_field['b'] if 'b' in title_field else \"\"\n",
        "                title_c = title_field['c'] if 'c' in title_field else \"\"\n",
        "                full_title = (title_a + \" \" + title_b + \" \" + title_c).strip()\n",
        "                graph.add((work_uri, BF.title, Literal(full_title.strip())))\n",
        "\n",
        "            # Author (100)\n",
        "            if '100' in record and 'a' in record['100']:\n",
        "                author_field = record['100']\n",
        "                author_name = author_field['a'].strip()\n",
        "                person_uri = None\n",
        "\n",
        "                # Check $1 and $0 for URI\n",
        "                one_val = author_field.get_subfields('1')\n",
        "                zero_val = author_field.get_subfields('0')\n",
        "\n",
        "                if one_val and one_val[0].startswith('http'):\n",
        "                    person_uri = URIRef(one_val[0].strip())\n",
        "                elif zero_val and zero_val[0].startswith('http'):\n",
        "                    person_uri = URIRef(zero_val[0].strip())\n",
        "                else:\n",
        "                    person_uri = URIRef(EX[f\"person/{hash(author_name)}\"])\n",
        "\n",
        "                graph.add((person_uri, BF.label, Literal(author_name)))\n",
        "                graph.add((work_uri, BF.contributor, person_uri))\n",
        "\n",
        "            # Edition (250)\n",
        "            if '250' in record and 'a' in record['250']:\n",
        "                edition = record['250']['a'].strip()\n",
        "                graph.add((instance_uri, BF.editionStatement, Literal(edition)))\n",
        "\n",
        "            # Publication info (264)\n",
        "            for field264 in record.get_fields('264'):\n",
        "                place = field264['a'] if 'a' in field264 else None\n",
        "                publisher = field264['b'] if 'b' in field264 else None\n",
        "                date = field264['c'] if 'c' in field264 else None\n",
        "                provision_uri = URIRef(EX[f\"provision/{record_id}/{hash(field264)}\"])\n",
        "                if place:\n",
        "                    graph.add((provision_uri, BF.place, Literal(place.strip())))\n",
        "                if publisher:\n",
        "                    graph.add((provision_uri, BF.agent, Literal(publisher.strip())))\n",
        "                if date:\n",
        "                    graph.add((provision_uri, BF.date, Literal(date.strip())))\n",
        "                graph.add((instance_uri, BF.provisionActivity, provision_uri))\n",
        "\n",
        "            # Physical description (300)\n",
        "            if '300' in record:\n",
        "                extent_parts = []\n",
        "                for sf_code in ['a','b','c']:\n",
        "                    if sf_code in record['300']:\n",
        "                        extent_parts.append(record['300'][sf_code].strip())\n",
        "                extent_str = \"; \".join(extent_parts)\n",
        "                if extent_str:\n",
        "                    graph.add((instance_uri, BF.extent, Literal(extent_str)))\n",
        "\n",
        "            # 334 - Mode of Issuance\n",
        "            for f334 in record.get_fields('334'):\n",
        "                if 'a' in f334:\n",
        "                    graph.add((work_uri, BF.modeOfIssuance, Literal(f334['a'].strip())))\n",
        "\n",
        "            # 336 (Content), 337 (Media), 338 (Carrier)\n",
        "            for f336 in record.get_fields('336'):\n",
        "                if 'a' in f336:\n",
        "                    graph.add((work_uri, BF.content, Literal(f336['a'].strip())))\n",
        "            for f337 in record.get_fields('337'):\n",
        "                if 'a' in f337:\n",
        "                    graph.add((instance_uri, BF.media, Literal(f337['a'].strip())))\n",
        "            for f338 in record.get_fields('338'):\n",
        "                if 'a' in f338:\n",
        "                    graph.add((instance_uri, BF.carrier, Literal(f338['a'].strip())))\n",
        "\n",
        "            # 340 - Physical Medium\n",
        "            for f340 in record.get_fields('340'):\n",
        "                sub_vals = f340.get_subfields()  # get all subfield values as strings\n",
        "                val = \" \".join(v.strip() for v in sub_vals if v and v.strip())\n",
        "                if val:\n",
        "                    graph.add((instance_uri, BF.note, Literal(\"Physical Medium: \" + val)))\n",
        "\n",
        "            # 347 - Digital file characteristics\n",
        "            for f347 in record.get_fields('347'):\n",
        "                sub_vals = f347.get_subfields()\n",
        "                val = \" \".join(v.strip() for v in sub_vals if v and v.strip())\n",
        "                if val:\n",
        "                    graph.add((instance_uri, BF.note, Literal(\"Digital File Characteristics: \" + val)))\n",
        "\n",
        "            # 380 - Form of work\n",
        "            for f380 in record.get_fields('380'):\n",
        "                if 'a' in f380:\n",
        "                    graph.add((work_uri, BF.genreForm, Literal(f380['a'].strip())))\n",
        "\n",
        "            # 388 - Time period of creation\n",
        "            for f388 in record.get_fields('388'):\n",
        "                if 'a' in f388:\n",
        "                    graph.add((work_uri, BF.temporalCoverage, Literal(f388['a'].strip())))\n",
        "\n",
        "            # 500 - General notes\n",
        "            for f500 in record.get_fields('500'):\n",
        "                sub_vals = f500.get_subfields()\n",
        "                note_val = \" \".join(v.strip() for v in sub_vals if v and v.strip())\n",
        "                if note_val:\n",
        "                    graph.add((instance_uri, BF.note, Literal(note_val)))\n",
        "\n",
        "            # 506 - Restrictions on Access\n",
        "            for f506 in record.get_fields('506'):\n",
        "                sub_vals = f506.get_subfields()\n",
        "                val = \" \".join(v.strip() for v in sub_vals if v and v.strip())\n",
        "                if val:\n",
        "                    graph.add((instance_uri, BF.usageAndAccessPolicy, Literal(val)))\n",
        "\n",
        "            # 561 - Provenance\n",
        "            for f561 in record.get_fields('561'):\n",
        "                sub_vals = f561.get_subfields()\n",
        "                val = \" \".join(v.strip() for v in sub_vals if v and v.strip())\n",
        "                if val:\n",
        "                    graph.add((instance_uri, BF.provenance, Literal(val)))\n",
        "\n",
        "            # 583 - Action notes\n",
        "            for f583 in record.get_fields('583'):\n",
        "                sub_vals = f583.get_subfields()\n",
        "                val = \" \".join(v.strip() for v in sub_vals if v and v.strip())\n",
        "                if val:\n",
        "                    graph.add((instance_uri, BF.note, Literal(\"Action: \" + val)))\n",
        "\n",
        "            # 655 - Genre/Form\n",
        "            for f655 in record.get_fields('655'):\n",
        "                if 'a' in f655:\n",
        "                    genre_val = f655['a'].strip()\n",
        "                    one_val = f655.get_subfields('1')\n",
        "                    genre_uri = None\n",
        "                    if one_val and one_val[0].startswith('http'):\n",
        "                        genre_uri = URIRef(one_val[0].strip())\n",
        "                    if genre_uri:\n",
        "                        graph.add((work_uri, BF.genreForm, genre_uri))\n",
        "                        graph.add((genre_uri, BF.label, Literal(genre_val)))\n",
        "                    else:\n",
        "                        graph.add((work_uri, BF.genreForm, Literal(genre_val)))\n",
        "\n",
        "            # 700 - Additional contributors\n",
        "            for f700 in record.get_fields('700'):\n",
        "                if 'a' in f700:\n",
        "                    contrib_name = f700['a'].strip()\n",
        "                    contrib_uri = None\n",
        "                    one_val = f700.get_subfields('1')\n",
        "                    zero_val = f700.get_subfields('0')\n",
        "                    if one_val and one_val[0].startswith('http'):\n",
        "                        contrib_uri = URIRef(one_val[0].strip())\n",
        "                    elif zero_val and zero_val[0].startswith('http'):\n",
        "                        contrib_uri = URIRef(zero_val[0].strip())\n",
        "                    else:\n",
        "                        contrib_uri = URIRef(EX[f\"person/{hash(contrib_name)}\"])\n",
        "\n",
        "                    graph.add((contrib_uri, BF.label, Literal(contrib_name)))\n",
        "                    graph.add((work_uri, BF.contributor, contrib_uri))\n",
        "\n",
        "            # 773 - Host Item Entry\n",
        "            for f773 in record.get_fields('773'):\n",
        "                host_title = f773['t'] if 't' in f773 else None\n",
        "                host_uri = None\n",
        "                if 'w' in f773:\n",
        "                    w_val = f773['w'].strip()\n",
        "                    host_uri = URIRef(EX[\"work/host/\"+w_val.replace(\"(\",\"\").replace(\")\",\"\").replace(\"OCoLC\",\"oclc\")])\n",
        "                else:\n",
        "                    host_uri = URIRef(EX[f\"work/host/{hash(host_title)}\"]) if host_title else URIRef(EX[f\"work/host/{hash(record_id)}\"])\n",
        "\n",
        "                if host_title:\n",
        "                    graph.add((host_uri, BF.title, Literal(host_title.strip())))\n",
        "                graph.add((work_uri, BF.partOf, host_uri))\n",
        "\n",
        "            # 856 - Electronic access\n",
        "            for f856 in record.get_fields('856'):\n",
        "                if 'u' in f856:\n",
        "                    url = f856['u'].strip()\n",
        "                    electronic_uri = URIRef(url)\n",
        "                    graph.add((instance_uri, BF.electronicLocator, electronic_uri))\n",
        "                    if '3' in f856:\n",
        "                        graph.add((electronic_uri, BF.label, Literal(f856['3'].strip())))\n",
        "                    if 'y' in f856:\n",
        "                        graph.add((electronic_uri, BF.label, Literal(f856['y'].strip())))\n",
        "\n",
        "            # 994 local field\n",
        "            for f994 in record.get_fields('994'):\n",
        "                sub_vals = f994.get_subfields()\n",
        "                val = \" \".join(v.strip() for v in sub_vals if v and v.strip())\n",
        "                if val:\n",
        "                    graph.add((instance_uri, BF.note, Literal(\"Local Processing: \" + val.strip())))\n",
        "\n",
        "print(\"MARC to BIBFRAME conversion completed.\")\n",
        "\n",
        "# Serialize the RDF graph to a Turtle file\n",
        "output_file = \"output_bibframe.ttl\"\n",
        "print(f\"Serializing the RDF graph to {output_file}...\")\n",
        "serialized_ttl = graph.serialize(format=\"turtle\")\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(serialized_ttl)\n",
        "\n",
        "print(f\"Conversion complete. Downloading {output_file}...\")\n",
        "files.download(output_file)\n",
        "\n",
        "print(\"Downloading BIBFRAME shapes for SHACL validation...\")\n",
        "!wget https://raw.githubusercontent.com/lcnetdev/bibframe-shapes/master/shapes/BIBFRAME-shapes.ttl -O bibframe-shapes.ttl\n",
        "\n",
        "from pyshacl import validate\n",
        "\n",
        "shapes_graph = Graph()\n",
        "shapes_graph.parse(\"bibframe-shapes.ttl\", format=\"turtle\")\n",
        "\n",
        "if len(graph) == 0:\n",
        "    print(\"Warning: The RDF graph is empty. Validation may fail or produce no output.\")\n",
        "\n",
        "print(\"Validating RDF against BIBFRAME SHACL shapes. This may take a moment...\")\n",
        "conforms, results_graph, results_text = validate(\n",
        "    data_graph=graph,\n",
        "    shacl_graph=shapes_graph,\n",
        "    inference=\"rdfs\",\n",
        "    debug=True\n",
        ")\n",
        "\n",
        "if conforms:\n",
        "    print(\"RDF conforms to BIBFRAME specifications. No errors found.\")\n",
        "else:\n",
        "    print(\"Validation errors detected:\")\n",
        "    print(results_text)"
      ]
    }
  ]
}