{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPNhJFs7bbMVJFXoOcI3SZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsandaver/hsandaver/blob/main/Machine_Learning_Fading_Simulator_Complex_Model_with_Hyperparameters_V4_Added_Feature_Engineering_with_Polynomial_Features-no-autodownload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6udVGxygq8a"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Updated Script with Enhanced Machine Learning Model:\n",
        "- Replaced Random Forest with XGBoost\n",
        "- Added Hyperparameter Tuning with GridSearchCV\n",
        "- Implemented Cross-Validation\n",
        "- Enhanced Synthetic Data Generation\n",
        "- Added Feature Engineering with Polynomial Features\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
        "\n",
        "# Function to install packages\n",
        "def install_packages(packages):\n",
        "    for package in packages:\n",
        "        if package == 'google.colab':\n",
        "            continue  # Skip installation as it's already available in Colab\n",
        "        try:\n",
        "            importlib.import_module(package)\n",
        "            logging.info(f\"Package '{package}' is already installed.\")\n",
        "        except ImportError:\n",
        "            print(f\"Installing package: {package}\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# List of required packages\n",
        "required_packages = [\n",
        "    'scikit-image', 'numpy', 'pandas', 'matplotlib',\n",
        "    'Pillow', 'scipy', 'sklearn', 'ipywidgets', 'xgboost'\n",
        "]\n",
        "install_packages(required_packages)\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from skimage import color\n",
        "from skimage.color import deltaE_ciede2000\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "from ipywidgets import VBox, Layout\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# For file uploads and downloads in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "except ImportError:\n",
        "    # Define dummy functions if not in Colab\n",
        "    class DummyFiles:\n",
        "        def upload(self):\n",
        "            print(\"File upload functionality is not implemented in this environment.\")\n",
        "            return {}\n",
        "        def download(self, filename):\n",
        "            print(f\"File download functionality is not available. File '{filename}' saved locally.\")\n",
        "    files = DummyFiles()\n",
        "\n",
        "# -----------------------------\n",
        "# Step 1: Data Upload and Preprocessing\n",
        "# -----------------------------\n",
        "\n",
        "def upload_file(prompt_message, file_types=None):\n",
        "    print(prompt_message)\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        logging.error(\"No file uploaded.\")\n",
        "        sys.exit(1)\n",
        "    filename = next(iter(uploaded))\n",
        "    if file_types and not filename.lower().endswith(file_types):\n",
        "        logging.error(f\"Uploaded file must be one of the following types: {file_types}\")\n",
        "        sys.exit(1)\n",
        "    logging.info(f\"Uploaded file: {filename}\")\n",
        "    return filename\n",
        "\n",
        "def load_and_clean_dataset(csv_filename):\n",
        "    try:\n",
        "        dataset = pd.read_csv(csv_filename)\n",
        "        required_columns = {'L', 'A', 'B', 'Color Name'}\n",
        "        if not required_columns.issubset(dataset.columns):\n",
        "            missing = required_columns - set(dataset.columns)\n",
        "            logging.error(f\"Dataset is missing required columns: {missing}\")\n",
        "            sys.exit(1)\n",
        "        dataset = dataset.replace([np.inf, -np.inf], np.nan).dropna(subset=['L', 'A', 'B'])\n",
        "        logging.info(f\"Dataset loaded with {len(dataset)} entries after cleaning.\")\n",
        "        return dataset\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to load dataset: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "def upload_and_process_image():\n",
        "    image_filename = upload_file(\"Please upload the image file you want to analyze.\", file_types=('.png', '.jpg', '.jpeg'))\n",
        "    try:\n",
        "        image = Image.open(image_filename).convert('RGB')\n",
        "        image_array = np.array(image).astype(np.float32) / 255.0\n",
        "        lab_image = color.rgb2lab(image_array)\n",
        "        logging.info(f\"Image '{image_filename}' loaded and converted to LAB color space.\")\n",
        "        return image, lab_image\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to process image: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "# -----------------------------\n",
        "# Step 2: Machine Learning Model Training\n",
        "# -----------------------------\n",
        "\n",
        "def create_synthetic_data(art_types, material_types, dye_types, valid_combinations, num_samples_per_combination=500):\n",
        "    \"\"\"\n",
        "    Create synthetic data with pollution and UV exposure for different art, material, and dye types.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)  # Ensure reproducibility\n",
        "    data_list = []\n",
        "    for art_type in art_types:\n",
        "        for material_type in material_types:\n",
        "            dye_type_options = [dye for art, material, dye in valid_combinations if art == art_type and material == material_type]\n",
        "            for dye_type in dye_type_options:\n",
        "                # Generate environmental factors\n",
        "                lux_hours = np.random.uniform(low=1000, high=100000, size=num_samples_per_combination)\n",
        "                uv_exposure = np.random.uniform(low=0.0, high=1.0, size=num_samples_per_combination)\n",
        "                temperature = np.random.uniform(low=-10, high=50, size=num_samples_per_combination)\n",
        "                humidity = np.random.uniform(low=0, high=100, size=num_samples_per_combination)\n",
        "                pollution = np.random.uniform(low=0, high=1.0, size=num_samples_per_combination)\n",
        "                year_of_manufacture = np.random.randint(low=1455, high=2020, size=num_samples_per_combination)\n",
        "\n",
        "                # Generate fading data using the updated function\n",
        "                L_fading, A_fading, B_fading = generate_fading_data(\n",
        "                    art_type, material_type, dye_type, lux_hours, uv_exposure, temperature, humidity, pollution, year_of_manufacture, num_samples_per_combination\n",
        "                )\n",
        "\n",
        "                # Create a DataFrame for each combination\n",
        "                data = pd.DataFrame({\n",
        "                    'art_type': art_type,\n",
        "                    'material_type': material_type,\n",
        "                    'dye_type': dye_type,\n",
        "                    'lux_hours': lux_hours,\n",
        "                    'uv_exposure': uv_exposure,\n",
        "                    'temperature': temperature,\n",
        "                    'humidity': humidity,\n",
        "                    'pollution': pollution,\n",
        "                    'year_of_manufacture': year_of_manufacture,\n",
        "                    'L_fading': L_fading,\n",
        "                    'A_fading': A_fading,\n",
        "                    'B_fading': B_fading\n",
        "                })\n",
        "                data_list.append(data)\n",
        "\n",
        "    # Return the combined DataFrame of all synthetic samples\n",
        "    return pd.concat(data_list, ignore_index=True)\n",
        "\n",
        "def generate_fading_data(art_type, material_type, dye_type, lux_hours, uv_exposure, temperature, humidity, pollution, year_of_manufacture, num_samples):\n",
        "    \"\"\"\n",
        "    This function simulates fading in LAB color space for various art and material types based on environmental\n",
        "    factors like light exposure, UV exposure, temperature, humidity, pollution, and year of manufacture.\n",
        "    \"\"\"\n",
        "    # Initialize fading values for LAB color components\n",
        "    L_fading = np.zeros(num_samples)\n",
        "    A_fading = np.zeros(num_samples)\n",
        "    B_fading = np.zeros(num_samples)\n",
        "\n",
        "    # Normalize lux_hours, uv_exposure, pollution (scale from 0 to 1)\n",
        "    lux_normalized = lux_hours / 100000  # Now ranges from 0.0 to 1.0\n",
        "    uv_normalized = np.minimum(uv_exposure, 1.0)  # Element-wise comparison to cap values at 1.0\n",
        "    pollution_normalized = pollution  # Pollution is normalized between 0.0 and 1.0\n",
        "\n",
        "    # UV threshold for safe exposure (based on research)\n",
        "    uv_threshold = 0.075  # 75 µW/lm, maximum safe UV exposure for sensitive materials\n",
        "\n",
        "    # Exposure factor including light, UV, and pollution\n",
        "    exposure_factor = lux_normalized + uv_normalized + pollution_normalized\n",
        "\n",
        "    # Year factor: Older materials are more fragile\n",
        "    year_factor = (2020 - year_of_manufacture) / 220.0  # Normalize based on ~220 years\n",
        "\n",
        "    # Apply fading logic for different art and material types\n",
        "    if material_type == 'Textiles' and dye_type == 'Natural':\n",
        "        # Textiles with natural dyes fade more from UV and pollution\n",
        "        L_fading += np.random.normal(loc=-5, scale=1.5, size=num_samples) * exposure_factor * year_factor\n",
        "        A_fading += np.random.normal(loc=-2, scale=1, size=num_samples) * exposure_factor * year_factor\n",
        "        B_fading += np.random.normal(loc=-2, scale=1, size=num_samples) * exposure_factor * year_factor\n",
        "\n",
        "    elif material_type == 'Paper with Black Text':\n",
        "        # Paper with black text is more sensitive to light and pollution\n",
        "        L_fading += np.random.normal(loc=-1, scale=0.5, size=num_samples) * lux_normalized * year_factor\n",
        "\n",
        "    # Adjust fading for UV-sensitive materials if UV exceeds safe levels\n",
        "    if np.any(uv_exposure > uv_threshold):\n",
        "        uv_impact = (uv_exposure - uv_threshold) * 10  # Higher impact for UV above the threshold\n",
        "        L_fading -= uv_impact\n",
        "        A_fading -= uv_impact / 2\n",
        "        B_fading -= uv_impact / 2\n",
        "\n",
        "    # Pollution increases yellowing (B component)\n",
        "    if 'Acidic' in material_type:\n",
        "        L_fading -= np.random.normal(loc=-2, scale=1, size=num_samples) * pollution_normalized\n",
        "        B_fading += np.random.normal(loc=3, scale=1, size=num_samples) * pollution_normalized  # Increase yellowing\n",
        "\n",
        "    # Ensure fading values stay within LAB limits\n",
        "    L_fading = np.clip(L_fading, -20, 0)\n",
        "    A_fading = np.clip(A_fading, -10, 10)\n",
        "    B_fading = np.clip(B_fading, -10, 10)\n",
        "\n",
        "    return L_fading, A_fading, B_fading\n",
        "\n",
        "def prepare_features(synthetic_data):\n",
        "    X_numeric = synthetic_data[['lux_hours', 'uv_exposure', 'temperature', 'humidity', 'pollution', 'year_of_manufacture']]  # Added pollution and year_of_manufacture\n",
        "    X_categorical = synthetic_data[['art_type', 'material_type', 'dye_type']]\n",
        "\n",
        "    X_categorical = X_categorical.fillna('None')\n",
        "    encoder = OneHotEncoder(sparse_output=False)\n",
        "    X_categorical_encoded = encoder.fit_transform(X_categorical)\n",
        "\n",
        "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "    X_numeric_poly = poly.fit_transform(X_numeric)\n",
        "\n",
        "    X = np.hstack((X_numeric_poly, X_categorical_encoded))\n",
        "    Y = synthetic_data[['L_fading', 'A_fading', 'B_fading']].values\n",
        "    return X, Y, encoder, poly\n",
        "\n",
        "def tqdm_grid_search_cv(grid_search, X, Y):\n",
        "    \"\"\"\n",
        "    This function wraps GridSearchCV with a progress bar using tqdm.\n",
        "    \"\"\"\n",
        "    n_candidates = len(grid_search.param_grid)  # Number of parameter combinations\n",
        "    n_folds = grid_search.cv  # Number of cross-validation folds\n",
        "    total_fits = n_candidates * n_folds  # Total number of fits to be done\n",
        "\n",
        "    with tqdm(total=total_fits, desc=\"GridSearchCV Progress\") as pbar:\n",
        "        # We update the progress bar after each fit\n",
        "        def on_fit_progress(**kwargs):\n",
        "            pbar.update(1)\n",
        "\n",
        "        # Set the verbose option to provide information on each fold\n",
        "        grid_search.verbose = 3  # This provides detailed output per fold\n",
        "        grid_search.fit(X, Y)  # Perform the grid search fitting\n",
        "\n",
        "    return grid_search.best_estimator_, grid_search.best_params_\n",
        "\n",
        "def train_ml_model(X, Y):\n",
        "    # Step 1: Normalize (scale) the data\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Step 2: Define the model (XGBoost)\n",
        "    xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "    multi_xgb = MultiOutputRegressor(xgb)\n",
        "\n",
        "    # Step 3: Define the parameter grid for GridSearchCV\n",
        "    param_grid = {\n",
        "        'estimator__n_estimators': [100, 200],\n",
        "        'estimator__max_depth': [3, 5, 7],\n",
        "        'estimator__learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "\n",
        "    # Step 4: Set up GridSearchCV for hyperparameter tuning\n",
        "    grid_search = GridSearchCV(\n",
        "        multi_xgb, param_grid, cv=3, scoring='neg_mean_squared_error'\n",
        "    )\n",
        "\n",
        "    # Step 5: Use tqdm to show progress bar during GridSearchCV\n",
        "    best_model, best_params = tqdm_grid_search_cv(grid_search, X_scaled, Y)\n",
        "\n",
        "    # Step 6: Print the best parameters found by the grid search\n",
        "    print(f\"Best parameters found: {best_params}\")\n",
        "\n",
        "    # Step 7: Perform 5-fold cross-validation with the best model\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    mse_scores = cross_val_score(\n",
        "        best_model, X_scaled, Y, cv=kf, scoring='neg_mean_squared_error'\n",
        "    )\n",
        "    avg_mse = -np.mean(mse_scores)\n",
        "\n",
        "    # Step 8: Print the average MSE from cross-validation\n",
        "    print(f\"Cross-validated MSE: {avg_mse:.4f}\")\n",
        "\n",
        "    # Return the best model and scaler for future use\n",
        "    return best_model, scaler, avg_mse\n",
        "\n",
        "# -----------------------------\n",
        "# Step 3: Art Type, Material Type, and Dye Type Selection and Exposure Simulation Functions\n",
        "# -----------------------------\n",
        "\n",
        "# Art Types\n",
        "art_types = [\n",
        "    'Chromolithograph Print',\n",
        "    'Sanguine Etching',\n",
        "    'Steel Engraving',\n",
        "    'None',  # Added for materials without artwork\n",
        "]\n",
        "\n",
        "# Material Types\n",
        "material_types = [\n",
        "    'Acidic Wove Paper',\n",
        "    'Acidic Rag Paper',\n",
        "    'Alkaline Wove Paper',\n",
        "    'Alkaline Rag Paper',\n",
        "    'Textiles',\n",
        "    'Paper with Black Text',\n",
        "]\n",
        "\n",
        "# Dye Types (for Textiles)\n",
        "dye_types = [\n",
        "    'Natural',\n",
        "    'Synthetic',\n",
        "]\n",
        "\n",
        "# Valid combinations of Art Type, Material Type, and Dye Type\n",
        "valid_combinations = [\n",
        "    # Art Type, Material Type, Dye Type\n",
        "    ('Chromolithograph Print', 'Acidic Wove Paper', None),\n",
        "    ('Sanguine Etching', 'Acidic Wove Paper', None),\n",
        "    ('Sanguine Etching', 'Acidic Rag Paper', None),\n",
        "    ('Sanguine Etching', 'Alkaline Wove Paper', None),\n",
        "    ('Sanguine Etching', 'Alkaline Rag Paper', None),\n",
        "    ('Steel Engraving', 'Acidic Wove Paper', None),\n",
        "    ('None', 'Textiles', 'Natural'),\n",
        "    ('None', 'Textiles', 'Synthetic'),\n",
        "    ('None', 'Paper with Black Text', None),\n",
        "    ('None', 'Acidic Wove Paper', None),\n",
        "    ('None', 'Acidic Rag Paper', None),\n",
        "    ('None', 'Alkaline Wove Paper', None),\n",
        "    ('None', 'Alkaline Rag Paper', None),\n",
        "    # Add other valid combinations as necessary\n",
        "]\n",
        "\n",
        "# Create Art Type dropdown\n",
        "art_type_dropdown = widgets.Dropdown(\n",
        "    options=art_types,\n",
        "    value=art_types[0],\n",
        "    description='Art Type:',\n",
        "    disabled=False,\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "# Create Material Type dropdown\n",
        "material_type_dropdown = widgets.Dropdown(\n",
        "    options=[],\n",
        "    description='Material Type:',\n",
        "    disabled=False,\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "# Create Dye Type dropdown (initially hidden)\n",
        "dye_type_dropdown = widgets.Dropdown(\n",
        "    options=[],\n",
        "    value=None,\n",
        "    description='Dye Type:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(visibility='hidden', width='500px'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Function to update Material Type options based on selected Art Type\n",
        "def update_material_type_options(*args):\n",
        "    selected_art_type = art_type_dropdown.value\n",
        "    valid_materials = [material for art, material, dye in valid_combinations if art == selected_art_type]\n",
        "    valid_materials = sorted(set(valid_materials))\n",
        "    material_type_dropdown.options = valid_materials\n",
        "    if material_type_dropdown.value not in valid_materials:\n",
        "        material_type_dropdown.value = valid_materials[0] if valid_materials else None\n",
        "    update_dye_type_visibility()\n",
        "\n",
        "def update_dye_type_visibility(*args):\n",
        "    selected_material_type = material_type_dropdown.value\n",
        "    if selected_material_type == 'Textiles':\n",
        "        dye_type_dropdown.layout.visibility = 'visible'\n",
        "        valid_dyes = [dye for art, material, dye in valid_combinations\n",
        "                      if material == selected_material_type and dye is not None]\n",
        "        valid_dyes = sorted(set(valid_dyes))\n",
        "        dye_type_dropdown.options = valid_dyes\n",
        "        if dye_type_dropdown.value not in valid_dyes:\n",
        "            dye_type_dropdown.value = valid_dyes[0] if valid_dyes else None\n",
        "    else:\n",
        "        dye_type_dropdown.layout.visibility = 'hidden'\n",
        "        dye_type_dropdown.options = []\n",
        "        dye_type_dropdown.value = None\n",
        "\n",
        "# Attach the update functions to the dropdowns\n",
        "art_type_dropdown.observe(update_material_type_options, names='value')\n",
        "material_type_dropdown.observe(update_dye_type_visibility, names='value')\n",
        "\n",
        "# Initial update of Material Type options\n",
        "update_material_type_options()\n",
        "\n",
        "# Arrange dropdowns vertically with spacing\n",
        "dropdown_layout = Layout(display='flex', flex_flow='column', align_items='stretch', width='500px')\n",
        "dropdowns = VBox([art_type_dropdown, material_type_dropdown, dye_type_dropdown], layout=dropdown_layout)\n",
        "\n",
        "# Display the dropdowns\n",
        "display(dropdowns)\n",
        "\n",
        "# Create the sliders with adjusted style and layout\n",
        "time_slider = widgets.FloatSlider(\n",
        "    value=5,\n",
        "    min=0,\n",
        "    max=100,\n",
        "    step=1,\n",
        "    description='Years of Aging:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "uv_slider = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0.0,\n",
        "    max=1.0,\n",
        "    step=0.01,\n",
        "    description='UV Exposure:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "lux_slider = widgets.FloatSlider(\n",
        "    value=50000,\n",
        "    min=0,\n",
        "    max=100000,\n",
        "    step=1000,\n",
        "    description='Lux Hours:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "humidity_slider = widgets.FloatSlider(\n",
        "    value=50,\n",
        "    min=0,\n",
        "    max=100,\n",
        "    step=1,\n",
        "    description='Humidity (%):',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "temp_slider = widgets.FloatSlider(\n",
        "    value=20,\n",
        "    min=-10,\n",
        "    max=50,\n",
        "    step=1,\n",
        "    description='Temperature (°C):',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "pollution_slider = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0,\n",
        "    max=1.0,\n",
        "    step=0.01,\n",
        "    description='Pollution Level:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "# Explanation of the pollution scale\n",
        "pollution_explanation = \"\"\"\n",
        "<h4>Pollution Scale Explanation:</h4>\n",
        "<ul>\n",
        "    <li><strong>0.0</strong>: Clean air with minimal pollution (e.g., rural or controlled environments).</li>\n",
        "    <li><strong>0.1 - 0.3</strong>: Low pollution, typical of areas with good air quality.</li>\n",
        "    <li><strong>0.4 - 0.6</strong>: Moderate pollution, like urban environments with traffic or industry.</li>\n",
        "    <li><strong>0.7 - 1.0</strong>: High pollution, found in industrial or heavily polluted areas.</li>\n",
        "</ul>\n",
        "<p>Higher pollution levels will increase the rate of fading and degradation of materials.</p>\n",
        "\"\"\"\n",
        "\n",
        "# Display the pollution slider\n",
        "\n",
        "year_slider = widgets.IntSlider(\n",
        "    value=2000,\n",
        "    min=1455,\n",
        "    max=2020,\n",
        "    step=1,\n",
        "    description='Year of Manufacture:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "# Arrange sliders vertically with spacing\n",
        "slider_layout = Layout(display='flex', flex_flow='column', align_items='stretch', width='500px')\n",
        "sliders = VBox([time_slider, uv_slider, lux_slider, humidity_slider, temp_slider, pollution_slider, year_slider], layout=slider_layout)\n",
        "\n",
        "# Display the sliders\n",
        "display(sliders)\n",
        "\n",
        "def simulate_exposure_by_material(lab_image, art_type, material_type, dye_type, exposure_years, uv_exposure, lux_hours, humidity, temperature):\n",
        "    lab_exposed = lab_image.copy()\n",
        "\n",
        "    # Normalize lux_hours and uv_exposure\n",
        "    lux_normalized = lux_hours / 100000  # Now ranges from 0.0 to 1.0\n",
        "    uv_normalized = uv_exposure  # Already between 0.0 and 1.0\n",
        "\n",
        "    # Combined exposure factor\n",
        "    exposure_factor = lux_normalized + uv_normalized\n",
        "    exposure_factor = np.clip(exposure_factor, 0, 2)  # Max exposure factor is 2\n",
        "\n",
        "    # Refined Material and Dye Interactions with Light (Lux Hours and UV)\n",
        "    if art_type == 'Chromolithograph Print':\n",
        "        lab_exposed[:, :, 0] -= ((lux_normalized * 10) + (uv_normalized * 10))\n",
        "        lab_exposed[:, :, 1] -= ((lux_normalized * 5) + (uv_normalized * 5))\n",
        "        lab_exposed[:, :, 2] -= ((lux_normalized * 5) + (uv_normalized * 5))\n",
        "    elif art_type == 'Sanguine Etching':\n",
        "        lab_exposed[:, :, 1] -= (lux_normalized * 10)\n",
        "    elif art_type == 'Steel Engraving':\n",
        "        lab_exposed[:, :, 0] -= (lux_normalized * 5)\n",
        "    elif art_type == 'None':\n",
        "        # No artwork-specific fading\n",
        "        pass\n",
        "\n",
        "    # Adjustments based on material type\n",
        "    if 'Acidic' in material_type:\n",
        "        lab_exposed[:, :, 0] -= uv_normalized * 10\n",
        "        lab_exposed[:, :, 2] += uv_normalized * 10  # Increase yellowing\n",
        "    elif 'Alkaline' in material_type:\n",
        "        lab_exposed[:, :, 0] -= lux_normalized * 5\n",
        "    elif material_type == 'Textiles':\n",
        "        if dye_type == 'Natural':\n",
        "            fading_multiplier = np.log(lux_hours + 1) / np.log(100000 + 1)\n",
        "            lab_exposed[:, :, 0] -= uv_normalized * 15 * fading_multiplier\n",
        "            lab_exposed[:, :, 1] -= uv_normalized * 15 * fading_multiplier\n",
        "            lab_exposed[:, :, 2] -= uv_normalized * 15 * fading_multiplier\n",
        "        elif dye_type == 'Synthetic':\n",
        "            lab_exposed[:, :, 0] -= uv_normalized * 10\n",
        "            lab_exposed[:, :, 1] -= uv_normalized * 10\n",
        "            lab_exposed[:, :, 2] -= uv_normalized * 10\n",
        "    elif material_type == 'Paper with Black Text':\n",
        "        lab_exposed[:, :, 0] -= lux_normalized * 2\n",
        "\n",
        "    # Ensure values stay within valid LAB ranges\n",
        "    lab_exposed[:, :, 0] = np.clip(lab_exposed[:, :, 0], 0, 100)\n",
        "    lab_exposed[:, :, 1] = np.clip(lab_exposed[:, :, 1], -128, 127)\n",
        "    lab_exposed[:, :, 2] = np.clip(lab_exposed[:, :, 2], -128, 127)\n",
        "\n",
        "    logging.info(f\"Simulated exposure for {art_type} on {material_type} with dye type {dye_type}.\")\n",
        "    return lab_exposed\n",
        "\n",
        "# Added missing function: lab_to_rgb\n",
        "def lab_to_rgb(lab_image):\n",
        "    rgb_image = color.lab2rgb(lab_image)\n",
        "    rgb_image = np.clip(rgb_image, 0, 1)\n",
        "    rgb_image = (rgb_image * 255).astype(np.uint8)\n",
        "    return rgb_image\n",
        "\n",
        "# Added missing function: display_image\n",
        "def display_image(image, title='Image', save_fig=False, filename=None):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    if save_fig and filename:\n",
        "        plt.savefig(filename, bbox_inches='tight')\n",
        "        logging.info(f\"Image saved as {filename}\")\n",
        "    plt.show()\n",
        "\n",
        "# Added missing function: apply_fading\n",
        "def apply_fading(lab_image, predicted_fading):\n",
        "    lab_faded = lab_image.copy()\n",
        "    lab_faded[:, :, 0] += predicted_fading[0]\n",
        "    lab_faded[:, :, 1] += predicted_fading[1]\n",
        "    lab_faded[:, :, 2] += predicted_fading[2]\n",
        "    lab_faded[:, :, 0] = np.clip(lab_faded[:, :, 0], 0, 100)\n",
        "    lab_faded[:, :, 1] = np.clip(lab_faded[:, :, 1], -128, 127)\n",
        "    lab_faded[:, :, 2] = np.clip(lab_faded[:, :, 2], -128, 127)\n",
        "    logging.info(\"Applied predicted fading to the image.\")\n",
        "    return lab_faded\n",
        "\n",
        "# -----------------------------\n",
        "# Step 4: Visualization and Delta-E\n",
        "# -----------------------------\n",
        "\n",
        "def compute_delta_e(lab1, lab2):\n",
        "    delta_e = deltaE_ciede2000(lab1, lab2)\n",
        "    logging.info(f\"Delta-E between the two images calculated.\")\n",
        "    return delta_e\n",
        "\n",
        "def display_color_difference(delta_e, title='Color Difference Map (∆E)', save_fig=False, filename=None):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(delta_e, cmap='hot')\n",
        "    plt.colorbar(label='∆E')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    if save_fig and filename:\n",
        "        plt.savefig(filename, bbox_inches='tight')\n",
        "        logging.info(f\"Color difference map saved as {filename}\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_histograms(image1, image2, title_suffix='', save_fig=False, filename=None):\n",
        "    import textwrap\n",
        "    image1_array = np.array(image1)\n",
        "    image2_array = np.array(image2)\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    colors = ['Red', 'Green', 'Blue']\n",
        "    for i, color_name in enumerate(colors):\n",
        "        axs[i].hist(image1_array[..., i].flatten(), bins=256, alpha=0.5, label=f'{color_name} (Image 1)', color=color_name.lower())\n",
        "        axs[i].hist(image2_array[..., i].flatten(), bins=256, alpha=0.5, label=f'{color_name} (Image 2)', color=f'dark{color_name.lower()}')\n",
        "        # Wrap the title to a maximum width\n",
        "        wrapped_title = textwrap.fill(f'{color_name} Channel {title_suffix}', width=25)\n",
        "        axs[i].set_title(wrapped_title, fontsize=10)\n",
        "        axs[i].legend()\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(wspace=0.4)  # Increase horizontal space between subplots\n",
        "    if save_fig and filename:\n",
        "        plt.savefig(filename, bbox_inches='tight')\n",
        "        logging.info(f\"Histogram saved as {filename}\")\n",
        "    plt.show()\n",
        "\n",
        "def display_average_color(image_lab, title='Average Color', save_fig=False, filename=None):\n",
        "    average_lab = image_lab.mean(axis=(0,1))\n",
        "    average_rgb = color.lab2rgb(np.reshape(average_lab, (1,1,3))).reshape(1,1,3)\n",
        "    average_rgb = np.clip(average_rgb, 0, 1)\n",
        "    plt.figure(figsize=(2,2))\n",
        "    plt.imshow(np.ones((100,100,3)) * average_rgb)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    if save_fig and filename:\n",
        "        plt.savefig(filename, bbox_inches='tight')\n",
        "        logging.info(f\"Average color saved as {filename}\")\n",
        "    plt.show()\n",
        "    logging.info(f\"{title}: L={average_lab[0]:.2f}, A={average_lab[1]:.2f}, B={average_lab[2]:.2f}\")\n",
        "    return average_lab\n",
        "\n",
        "# New function to compute Delta-E between average colors\n",
        "def compute_average_delta_e(avg_lab1, avg_lab2):\n",
        "    lab1 = np.array([avg_lab1])\n",
        "    lab2 = np.array([avg_lab2])\n",
        "    delta_e = deltaE_ciede2000(lab1, lab2)[0]\n",
        "    logging.info(f\"Delta-E between average colors: {delta_e:.2f}\")\n",
        "    return delta_e\n",
        "\n",
        "# -----------------------------\n",
        "# Step 5: Main Execution Flow\n",
        "# -----------------------------\n",
        "\n",
        "def main():\n",
        "    # Upload and load dataset\n",
        "    csv_filename = upload_file(\"Please upload your LAB color dataset CSV file.\", file_types=('.csv',))\n",
        "    dataset = load_and_clean_dataset(csv_filename)\n",
        "\n",
        "    # Upload and process image\n",
        "    original_image, original_lab = upload_and_process_image()\n",
        "\n",
        "    # Display average color before fading\n",
        "    avg_lab_before = display_average_color(original_lab, title='Average Color - Original Image', save_fig=True, filename='average_color_before.png')\n",
        "\n",
        "    # Create synthetic data and train model\n",
        "    synthetic_data = create_synthetic_data(art_types, material_types, dye_types, valid_combinations, num_samples_per_combination=500)\n",
        "    X, Y, encoder, poly = prepare_features(synthetic_data)\n",
        "    model, scaler, mse = train_ml_model(X, Y)\n",
        "    print(f\"Cross-validated Mean Squared Error for Fading Prediction: {mse:.4f}\")\n",
        "\n",
        "    # Get environmental parameters\n",
        "    art_type = art_type_dropdown.value\n",
        "    material_type = material_type_dropdown.value\n",
        "    dye_type = dye_type_dropdown.value if dye_type_dropdown.layout.visibility == 'visible' else 'None'\n",
        "    exposure_years = time_slider.value\n",
        "    uv_exposure = uv_slider.value\n",
        "    lux_hours = lux_slider.value\n",
        "    humidity = humidity_slider.value\n",
        "    temperature = temp_slider.value\n",
        "    pollution = pollution_slider.value\n",
        "    year_of_manufacture = year_slider.value\n",
        "\n",
        "    # Simulate exposure by material\n",
        "    lab_exposed = simulate_exposure_by_material(original_lab, art_type, material_type, dye_type, exposure_years, uv_exposure, lux_hours, humidity, temperature)\n",
        "    exposed_image = lab_to_rgb(lab_exposed)\n",
        "    display_image(exposed_image, title=f'Simulated Exposure: {art_type} on {material_type}', save_fig=True, filename='exposed_image.png')\n",
        "\n",
        "    # Display average color after simulated exposure\n",
        "    avg_lab_exposed = display_average_color(lab_exposed, title='Average Color - Simulated Exposure', save_fig=True, filename='average_color_exposed.png')\n",
        "\n",
        "    # Compute Delta-E between Original and Simulated Exposure\n",
        "    delta_e_simulation = compute_delta_e(original_lab, lab_exposed)\n",
        "    display_color_difference(delta_e_simulation, title='Color Difference Map (∆E) - Original vs Simulated Exposure', save_fig=True, filename='delta_e_simulation.png')\n",
        "    delta_e_avg_simulation = compute_average_delta_e(avg_lab_before, avg_lab_exposed)\n",
        "    print(f\"Delta-E between average colors (Original vs Simulated Exposure): {delta_e_avg_simulation:.2f}\")\n",
        "\n",
        "    # Plot histograms between Original and Simulated Exposure\n",
        "    plot_histograms(original_image, exposed_image, title_suffix='Original vs Simulated Exposure', save_fig=True, filename='histograms_simulation.png')\n",
        "\n",
        "    # Prepare features for prediction\n",
        "    # One-hot encode the selected art type, material type, and dye type\n",
        "    categorical_input = pd.DataFrame({'art_type': [art_type], 'material_type': [material_type], 'dye_type': [dye_type]})\n",
        "    categorical_input = categorical_input.fillna('None')\n",
        "    categorical_encoded = encoder.transform(categorical_input)\n",
        "\n",
        "    # Create polynomial features for the numeric input\n",
        "    X_input_numeric = np.array([[lux_hours, uv_exposure, temperature, humidity, pollution, year_of_manufacture]])\n",
        "    X_input_numeric_poly = poly.transform(X_input_numeric)\n",
        "\n",
        "    # Combine numeric and categorical features\n",
        "    X_input = np.hstack((X_input_numeric_poly, categorical_encoded))\n",
        "    X_input_scaled = scaler.transform(X_input)\n",
        "\n",
        "    # Predict fading and apply it\n",
        "    predicted_fading = model.predict(X_input_scaled)[0]\n",
        "    lab_faded = apply_fading(lab_exposed, predicted_fading)\n",
        "    faded_image = lab_to_rgb(lab_faded)\n",
        "    display_image(faded_image, title=f'Faded Image After ML Prediction', save_fig=True, filename='faded_image.png')\n",
        "\n",
        "    # Display average color after fading\n",
        "    avg_lab_after = display_average_color(lab_faded, title='Average Color - After ML Prediction', save_fig=True, filename='average_color_after.png')\n",
        "\n",
        "    # Compute Delta-E between Simulated Exposure and ML Prediction\n",
        "    delta_e_ml = compute_delta_e(lab_exposed, lab_faded)\n",
        "    display_color_difference(delta_e_ml, title='Color Difference Map (∆E) - Simulated Exposure vs ML Prediction', save_fig=True, filename='delta_e_ml.png')\n",
        "    delta_e_avg_ml = compute_average_delta_e(avg_lab_exposed, avg_lab_after)\n",
        "    print(f\"Delta-E between average colors (Simulated Exposure vs ML Prediction): {delta_e_avg_ml:.2f}\")\n",
        "\n",
        "    # Compute Delta-E between Original and Final Faded Image\n",
        "    delta_e_total = compute_delta_e(original_lab, lab_faded)\n",
        "    display_color_difference(delta_e_total, title='Color Difference Map (∆E) - Original vs Final Faded', save_fig=True, filename='delta_e_total.png')\n",
        "    delta_e_avg_total = compute_average_delta_e(avg_lab_before, avg_lab_after)\n",
        "    print(f\"Delta-E between average colors (Original vs Final Faded): {delta_e_avg_total:.2f}\")\n",
        "\n",
        "    # Plot histograms between Original and Final Faded Image\n",
        "    plot_histograms(original_image, faded_image, title_suffix='Original vs Final Faded', save_fig=True, filename='histograms_final.png')\n",
        "\n",
        "# Create a 'Run Simulation' button and output area\n",
        "run_button = widgets.Button(description='Run Simulation', layout=widgets.Layout(width='200px'))\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        main()\n",
        "\n",
        "run_button.on_click(on_button_clicked)\n",
        "\n",
        "# Arrange button and output\n",
        "interface_layout = VBox([run_button, output], layout=Layout(align_items='center'))\n",
        "\n",
        "# Display the button and output\n",
        "display(interface_layout)"
      ]
    }
  ]
}